2018-04-10 23:54:51,078:


Neural Network Architecture         
Layers:                                1
Input Neurons:                      0030
Hidden Neurons:                     0040
Output Neurons:                     0001
Total Number of Parameters:         1281
Output activation:                  sigmoid
Inner activation:                   tanh

2018-04-10 23:54:51,102:
Check Backpropagation(Difference between Numerical Gradient and Analytical Gradient): 2.4514E-10

2018-04-10 23:54:51,109:Regularization           : 0.5000
2018-04-10 23:54:51,109:Maxiters                 :   3000
2018-04-10 23:54:51,145:Load                     : True  
2018-04-10 23:54:51,145:File                     : savedData/04-10_22-54-12_ACC_TR-0.9139_ACC_TE-0.8818_FC-0.2604_REG_0.500_HN1-040_I-03000_para.csv

2018-04-10 23:54:51,147:Training Neural Network...

2018-04-11 00:06:20,220:Finish Training...

2018-04-11 00:06:20,221:Regularization: 0.5000
2018-04-11 00:06:20,221:Iterations: 3000
2018-04-11 00:06:20,221:Gradient Descent Execution time: 689.035
2018-04-11 00:06:20,221:Initial Cost: 0.26040
2018-04-11 00:06:20,221:Final Cost: 0.25537
2018-04-11 00:06:20,254:Model evaluation

2018-04-11 00:06:20,254:Accuracy in training Set: 0.91661
2018-04-11 00:06:20,256:Accuracy in test Set (Exact Gradient): 0.88037
